import os
import time
import random
from dataclasses import dataclass
from io import BytesIO
from typing import List, Dict, Any

import streamlit as st
import yaml
from openai import OpenAI
import google.generativeai as genai
import anthropic
from xai_sdk import Client as XAIClient
from xai_sdk.chat import user as xai_user, system as xai_system

import docx2txt
from PyPDF2 import PdfReader
from fpdf import FPDF


# =========================
#  Localization
# =========================

UI_TEXT = {
    "en": {
        "app_title": "AuditFlow AI Â· Masterpiece Edition (FDA)",
        "subtitle": "FDA-oriented agentic document intelligence with painterly themes.",
        "tab_file_transform": "File Transform & Deep Summary",
        "tab_file_intel": "File Intelligence",
        "tab_multi_file": "Multi-File Synthesis",
        "tab_smart_replace": "Smart Replace",
        "tab_note_keeper": "AI Note Keeper",
        "upload_label": "Upload a document (PDF, DOCX, TXT):",
        "output_format": "Transform file into:",
        "format_markdown": "Markdown (.md)",
        "format_pdf": "PDF (.pdf)",
        "run_summary": "Generate 2,000â€“3,000 word Masterpiece summary",
        "chat_with_file": "Chat with this file",
        "api_key_section": "API Keys (browser-only, never sent to any server except LLM provider)",
        "provider": "Provider",
        "model": "Model",
        "custom_prompt": "Custom system prompt",
        "max_tokens": "Max tokens",
        "temperature": "Temperature",
        "user_prompt": "Your question / instruction",
        "agent_select": "FDA Agent (from advanced_agents.yaml)",
    },
    "zh": {
        "app_title": "AuditFlow AI Â· å¤§å¸«å‚‘ä½œç‰ˆï¼ˆFDA å°ˆç”¨ï¼‰",
        "subtitle": "é¢å‘ FDA å ±è¦èˆ‡åˆè¦éœ€æ±‚çš„ä»£ç†å¼æ–‡ä»¶æ™ºæ…§ç³»çµ±ï¼Œçµåˆè—è¡“é¢¨æ ¼é«”é©—ã€‚",
        "tab_file_transform": "æª”æ¡ˆè½‰æ›èˆ‡æ·±åº¦æ‘˜è¦",
        "tab_file_intel": "å–®ä¸€æ–‡ä»¶åˆ†æ",
        "tab_multi_file": "å¤šæ–‡ä»¶ç¶œåˆåˆ†æ",
        "tab_smart_replace": "æ™ºæ…§ç¯„æœ¬å¡«å¯«",
        "tab_note_keeper": "AI ç­†è¨˜ç®¡ç†å“¡",
        "upload_label": "ä¸Šå‚³æ–‡ä»¶ï¼ˆPDFã€DOCXã€TXTï¼‰ï¼š",
        "output_format": "å°‡æª”æ¡ˆè½‰æ›ç‚ºï¼š",
        "format_markdown": "Markdown (.md)",
        "format_pdf": "PDF (.pdf)",
        "run_summary": "ç”¢ç”Ÿ 2,000â€“3,000 å­—æ·±åº¦æ‘˜è¦ï¼ˆMarkdownï¼‰",
        "chat_with_file": "é‡å°æ­¤æ–‡ä»¶ç™¼å•",
        "api_key_section": "API é‡‘é‘°ï¼ˆåƒ…åœ¨æœ¬æ©Ÿç€è¦½å™¨ä¸­ä½¿ç”¨ï¼Œåƒ…é€å¾€ LLM ä¾›æ‡‰å•†ï¼‰",
        "provider": "æœå‹™æä¾›è€…",
        "model": "æ¨¡å‹",
        "custom_prompt": "è‡ªè¨‚ç³»çµ±æç¤ºï¼ˆSystem Promptï¼‰",
        "max_tokens": "æœ€å¤§ Token æ•¸",
        "temperature": "æº«åº¦",
        "user_prompt": "ä½ çš„å•é¡Œ / æŒ‡ä»¤",
        "agent_select": "FDA ä»£ç†äººï¼ˆä¾†è‡ª advanced_agents.yamlï¼‰",
    },
}


def t(key: str) -> str:
    lang = st.session_state.get("ui_lang", "en")
    return UI_TEXT.get(lang, UI_TEXT["en"]).get(key, key)


# =========================
#  Painter Styles
# =========================

@dataclass
class ArtistStyle:
    key: str
    display_name: str
    painter: str
    bg_gradient_light: str
    bg_gradient_dark: str
    panel_bg_rgba: str
    accent_color: str
    accent_soft: str
    font_family: str


ARTIST_STYLES: List[ArtistStyle] = [
    ArtistStyle(
        key="van_gogh",
        display_name="Starry Night",
        painter="Vincent van Gogh",
        bg_gradient_light="linear-gradient(135deg,#fdfbfb 0%,#ebedee 100%)",
        bg_gradient_dark="linear-gradient(135deg,#0f172a 0%,#1e293b 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.75)",
        accent_color="#facc15",
        accent_soft="#fef9c3",
        font_family="'DM Sans', system-ui, -apple-system, BlinkMacSystemFont, sans-serif",
    ),
    ArtistStyle(
        key="monet",
        display_name="Water Lilies",
        painter="Claude Monet",
        bg_gradient_light="linear-gradient(135deg,#e0f4ff 0%,#f9f7ff 100%)",
        bg_gradient_dark="linear-gradient(135deg,#0b1120 0%,#1d2233 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.70)",
        accent_color="#22c55e",
        accent_soft="#dcfce7",
        font_family="'Playfair Display', Georgia, 'Times New Roman', serif",
    ),
    ArtistStyle(
        key="picasso",
        display_name="Cubist Geometry",
        painter="Pablo Picasso",
        bg_gradient_light="linear-gradient(135deg,#fdfbfb 0%,#ebedee 40%,#fee2e2 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#111827 50%,#1f2933 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.80)",
        accent_color="#f97316",
        accent_soft="#ffedd5",
        font_family="'Space Grotesk', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="da_vinci",
        display_name="Renaissance Studio",
        painter="Leonardo da Vinci",
        bg_gradient_light="linear-gradient(135deg,#faf5e4 0%,#fef9c3 100%)",
        bg_gradient_dark="linear-gradient(135deg,#1c1917 0%,#292524 100%)",
        panel_bg_rgba="rgba(24, 24, 27, 0.85)",
        accent_color="#fbbf24",
        accent_soft="#fef3c7",
        font_family="'Crimson Text', Georgia, 'Times New Roman', serif",
    ),
    ArtistStyle(
        key="michelangelo",
        display_name="Sistine Ceiling",
        painter="Michelangelo",
        bg_gradient_light="linear-gradient(135deg,#e5e7eb 0%,#f9fafb 100%)",
        bg_gradient_dark="linear-gradient(135deg,#111827 0%,#020617 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.78)",
        accent_color="#60a5fa",
        accent_soft="#dbeafe",
        font_family="'Playfair Display', Georgia, serif",
    ),
    ArtistStyle(
        key="rembrandt",
        display_name="Chiaroscuro",
        painter="Rembrandt",
        bg_gradient_light="linear-gradient(135deg,#fef3c7 0%,#fed7aa 100%)",
        bg_gradient_dark="linear-gradient(135deg,#0b1120 0%,#1f2937 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.9)",
        accent_color="#f97316",
        accent_soft="#ffedd5",
        font_family="'Merriweather', Georgia, serif",
    ),
    ArtistStyle(
        key="klimt",
        display_name="Golden Mosaic",
        painter="Gustav Klimt",
        bg_gradient_light="linear-gradient(135deg,#fef3c7 0%,#facc15 50%,#fee2e2 100%)",
        bg_gradient_dark="linear-gradient(135deg,#1c1917 0%,#3f3f46 100%)",
        panel_bg_rgba="rgba(24, 24, 27, 0.85)",
        accent_color="#eab308",
        accent_soft="#fef9c3",
        font_family="'Cormorant Garamond', Georgia, serif",
    ),
    ArtistStyle(
        key="matisse",
        display_name="Cut-Outs",
        painter="Henri Matisse",
        bg_gradient_light="linear-gradient(135deg,#fee2e2 0%,#f9a8d4 50%,#bfdbfe 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#0f172a 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.9)",
        accent_color="#ec4899",
        accent_soft="#fce7f3",
        font_family="'Fredoka', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="dali",
        display_name="Surreal Desert",
        painter="Salvador DalÃ­",
        bg_gradient_light="linear-gradient(135deg,#fef3c7 0%,#fde68a 40%,#bfdbfe 100%)",
        bg_gradient_dark="linear-gradient(135deg,#111827 0%,#1f2937 100%)",
        panel_bg_rgba="rgba(17, 24, 39, 0.85)",
        accent_color="#f97316",
        accent_soft="#ffedd5",
        font_family="'IBM Plex Sans', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="warhol",
        display_name="Pop Factory",
        painter="Andy Warhol",
        bg_gradient_light="linear-gradient(135deg,#f9a8d4 0%,#f97316 40%,#22c55e 70%,#38bdf8 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#111827 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.9)",
        accent_color="#ec4899",
        accent_soft="#fee2e2",
        font_family="'Poppins', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="hokusai",
        display_name="Great Wave",
        painter="Hokusai",
        bg_gradient_light="linear-gradient(135deg,#e0f2fe 0%,#bfdbfe 40%,#f1f5f9 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#0f172a 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.9)",
        accent_color="#0ea5e9",
        accent_soft="#dbeafe",
        font_family="'Noto Sans TC', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="frida",
        display_name="Vivid Blossoms",
        painter="Frida Kahlo",
        bg_gradient_light="linear-gradient(135deg,#fee2e2 0%,#fecaca 40%,#bbf7d0 100%)",
        bg_gradient_dark="linear-gradient(135deg,#0f172a 0%,#1e293b 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.85)",
        accent_color="#f97316",
        accent_soft="#ffedd5",
        font_family="'Josefin Sans', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="banksy",
        display_name="Street Brutalism",
        painter="Banksy",
        bg_gradient_light="linear-gradient(135deg,#e5e7eb 0%,#9ca3af 40%,#111827 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#111827 100%)",
        panel_bg_rgba="rgba(17, 24, 39, 0.95)",
        accent_color="#f97316",
        accent_soft="#fee2e2",
        font_family="'Roboto Mono', ui-monospace, SFMono-Regular, Menlo, Monaco, monospace",
    ),
    ArtistStyle(
        key="rothko",
        display_name="Color Fields",
        painter="Mark Rothko",
        bg_gradient_light="linear-gradient(135deg,#fecaca 0%,#fed7aa 40%,#fef9c3 100%)",
        bg_gradient_dark="linear-gradient(135deg,#111827 0%,#1f2937 100%)",
        panel_bg_rgba="rgba(17, 24, 39, 0.9)",
        accent_color="#fb7185",
        accent_soft="#fee2e2",
        font_family="'Work Sans', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="chagall",
        display_name="Dreamscapes",
        painter="Marc Chagall",
        bg_gradient_light="linear-gradient(135deg,#e0e7ff 0%,#f5d0fe 40%,#cffafe 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#0f172a 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.9)",
        accent_color="#a855f7",
        accent_soft="#ede9fe",
        font_family="'Quicksand', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="basquiat",
        display_name="Neo-Expressionism",
        painter="Jean-Michel Basquiat",
        bg_gradient_light="linear-gradient(135deg,#fee2e2 0%,#f97316 30%,#22c55e 60%,#38bdf8 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#0f172a 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.95)",
        accent_color="#facc15",
        accent_soft="#fef3c7",
        font_family="'Inter', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="turner",
        display_name="Storm Light",
        painter="J. M. W. Turner",
        bg_gradient_light="linear-gradient(135deg,#fef3c7 0%,#fde68a 50%,#bfdbfe 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#111827 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.85)",
        accent_color="#f59e0b",
        accent_soft="#fef3c7",
        font_family="'DM Serif Display', Georgia, serif",
    ),
    ArtistStyle(
        key="vermeer",
        display_name="Soft Interior",
        painter="Johannes Vermeer",
        bg_gradient_light="linear-gradient(135deg,#e5e7eb 0%,#e0f2fe 50%,#fef9c3 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#0f172a 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.85)",
        accent_color="#38bdf8",
        accent_soft="#dbeafe",
        font_family="'Lora', Georgia, serif",
    ),
    ArtistStyle(
        key="cezanne",
        display_name="Mountain Geometry",
        painter="Paul CÃ©zanne",
        bg_gradient_light="linear-gradient(135deg,#e0f2fe 0%,#bbf7d0 50%,#fee2e2 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#0f172a 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.9)",
        accent_color="#22c55e",
        accent_soft="#dcfce7",
        font_family="'Source Sans 3', system-ui, sans-serif",
    ),
    ArtistStyle(
        key="pollock",
        display_name="Action Painting",
        painter="Jackson Pollock",
        bg_gradient_light="linear-gradient(135deg,#f1f5f9 0%,#e5e7eb 30%,#fecaca 60%,#bef264 100%)",
        bg_gradient_dark="linear-gradient(135deg,#020617 0%,#111827 100%)",
        panel_bg_rgba="rgba(15, 23, 42, 0.95)",
        accent_color="#f97316",
        accent_soft="#fed7aa",
        font_family="'Manrope', system-ui, sans-serif",
    ),
]


def apply_theme(style: ArtistStyle, dark_mode: bool):
    bg = style.bg_gradient_dark if dark_mode else style.bg_gradient_light
    panel = style.panel_bg_rgba
    text_color = "#e5e7eb" if dark_mode else "#020617"

    css = f"""
    <style>
    html, body, [data-testid="stAppViewContainer"] {{
        background: {bg} !important;
        background-attachment: fixed;
        font-family: {style.font_family};
        color: {text_color};
    }}
    .glass-panel {{
        background: {panel};
        backdrop-filter: blur(18px);
        -webkit-backdrop-filter: blur(18px);
        border-radius: 20px;
        border: 1px solid rgba(255,255,255,0.18);
        padding: 1.25rem 1.5rem;
        margin-bottom: 1.5rem;
    }}
    .accent-title {{
        color: {style.accent_color};
    }}
    .accent-chip {{
        background: {style.accent_soft};
        color: #111827;
        border-radius: 9999px;
        padding: 0.15rem 0.7rem;
        font-size: 0.75rem;
        font-weight: 500;
        display: inline-flex;
        align-items: center;
        gap: 0.25rem;
    }}
    textarea, .stTextInput > div > div > input {{
        background: rgba(15,23,42,0.75) !important;
        color: #e5e7eb !important;
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)


def style_selector_ui() -> ArtistStyle:
    st.markdown("### ğŸ¨ Masterpiece Style Jackpot")
    style_keys = [s.key for s in ARTIST_STYLES]
    current_style_key = st.session_state.get("artist_style_key", "van_gogh")

    col1, col2 = st.columns([3, 1])
    with col1:
        selected_key = st.selectbox(
            "Style",
            options=style_keys,
            index=style_keys.index(current_style_key) if current_style_key in style_keys else 0,
            format_func=lambda k: next(s.display_name for s in ARTIST_STYLES if s.key == k),
            key="artist_style_dropdown",
        )
    with col2:
        if st.button("Inspire Me (Jackpot)"):
            placeholder = st.empty()
            for _ in range(15):
                rand_key = random.choice(style_keys)
                st.session_state.artist_style_key = rand_key
                placeholder.write(
                    f"ğŸ° ğŸ¨ {next(s.display_name for s in ARTIST_STYLES if s.key == rand_key)}"
                )
                time.sleep(0.06)
            placeholder.empty()

    st.session_state.artist_style_key = st.session_state.get("artist_style_key", selected_key)
    active_style = next(s for s in ARTIST_STYLES if s.key == st.session_state.artist_style_key)
    return active_style


# =========================
#  Agents (from YAML)
# =========================

def load_agents(path: str = "advanced_agents.yaml") -> List[Dict[str, Any]]:
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        return data.get("agents", [])
    except Exception as e:
        st.sidebar.error(f"Failed to load agents YAML: {e}")
        return []


def agent_selector_ui(agents: List[Dict[str, Any]]) -> Dict[str, Any]:
    if not agents:
        st.sidebar.warning("No agents loaded from advanced_agents.yaml.")
        return {}

    st.sidebar.markdown(f"### ğŸ¤– {t('agent_select')}")
    ids = [a["id"] for a in agents]

    def label_func(agent_id: str) -> str:
        a = next(ag for ag in agents if ag["id"] == agent_id)
        return a.get("display_name_zh", agent_id)

    default_idx = 0
    if "selected_agent_id" in st.session_state:
        try:
            default_idx = ids.index(st.session_state["selected_agent_id"])
        except ValueError:
            default_idx = 0

    selected_id = st.sidebar.selectbox(
        "Agent",
        options=ids,
        index=default_idx,
        format_func=label_func,
        key="agent_selectbox",
    )
    selected_agent = next(a for a in agents if a["id"] == selected_id)

    # When agent changes, overwrite model & prompt defaults
    if st.session_state.get("selected_agent_id") != selected_id:
        st.session_state["selected_agent_id"] = selected_id
        # Defaults from agent config
        st.session_state["llm_provider"] = selected_agent.get("default_provider", "Gemini")
        st.session_state["llm_model_id"] = selected_agent.get("default_model", "gemini-3-flash")
        st.session_state["llm_max_tokens"] = selected_agent.get("default_max_tokens", 4096)
        st.session_state["llm_temperature"] = selected_agent.get("default_temperature", 0.3)
        st.session_state["llm_system_prompt"] = selected_agent.get(
            "system_prompt_zh",
            "ä½ æ˜¯ä¸€ä½ FDA æ³•è¦åˆè¦èˆ‡ç­–ç•¥åˆ†æå°ˆå®¶ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚",
        )

    return selected_agent


# =========================
#  API Keys
# =========================

def get_env_or_session_api_key(session_key: str, env_var: str) -> str:
    if session_key in st.session_state and st.session_state[session_key]:
        return st.session_state[session_key]

    env_val = os.getenv(env_var)
    if env_val:
        # Use environment key silently
        st.session_state[session_key] = env_val
        return env_val
    return ""


def render_api_key_inputs():
    st.sidebar.markdown(f"### ğŸ” {t('api_key_section')}")
    with st.sidebar.expander("OpenAI", expanded=False):
        env_val = os.getenv("OPENAI_API_KEY")
        if env_val:
            st.markdown("Using environment OpenAI API keyï¼ˆä¸é¡¯ç¤ºå¯¦éš›å€¼ï¼‰ã€‚")
            st.session_state["openai_api_key"] = env_val
        else:
            st.session_state["openai_api_key"] = st.text_input(
                "OpenAI API Key",
                type="password",
                value=st.session_state.get("openai_api_key", ""),
            )

    with st.sidebar.expander("Gemini", expanded=False):
        env_val = os.getenv("GEMINI_API_KEY")
        if env_val:
            st.markdown("Using environment Gemini API keyï¼ˆä¸é¡¯ç¤ºå¯¦éš›å€¼ï¼‰ã€‚")
            st.session_state["gemini_api_key"] = env_val
        else:
            st.session_state["gemini_api_key"] = st.text_input(
                "Gemini API Key",
                type="password",
                value=st.session_state.get("gemini_api_key", ""),
            )

    with st.sidebar.expander("Anthropic", expanded=False):
        env_val = os.getenv("ANTHROPIC_API_KEY")
        if env_val:
            st.markdown("Using environment Anthropic API keyï¼ˆä¸é¡¯ç¤ºå¯¦éš›å€¼ï¼‰ã€‚")
            st.session_state["anthropic_api_key"] = env_val
        else:
            st.session_state["anthropic_api_key"] = st.text_input(
                "Anthropic API Key",
                type="password",
                value=st.session_state.get("anthropic_api_key", ""),
            )

    with st.sidebar.expander("XAI (Grok)", expanded=False):
        env_val = os.getenv("XAI_API_KEY")
        if env_val:
            st.markdown("Using environment XAI API keyï¼ˆä¸é¡¯ç¤ºå¯¦éš›å€¼ï¼‰ã€‚")
            st.session_state["xai_api_key"] = env_val
        else:
            st.session_state["xai_api_key"] = st.text_input(
                "XAI API Key",
                type="password",
                value=st.session_state.get("xai_api_key", ""),
            )


# =========================
#  Model & Prompt Controls
# =========================

MODEL_CATALOG = {
    "OpenAI": [
        {"id": "gpt-4o-mini", "label": "GPTâ€‘4o mini"},
        {"id": "gpt-4.1-mini", "label": "GPTâ€‘4.1 mini"},
    ],
    "Gemini": [
        {"id": "gemini-2.5-flash", "label": "Gemini 2.5 Flash"},
        {"id": "gemini-3-flash", "label": "Gemini 3 Flash"},
    ],
    "Anthropic": [
        {"id": "claude-3.5-sonnet", "label": "Claude 3.5 Sonnet"},
        {"id": "claude-3.5-haiku", "label": "Claude 3.5 Haiku"},
    ],
    "XAI (Grok)": [
        {"id": "grok-4", "label": "Grok-4 (XAI)"},
    ],
}


def render_llm_controls():
    st.sidebar.markdown("### ğŸ§  LLM & Prompt")
    provider = st.sidebar.selectbox(
        t("provider"),
        list(MODEL_CATALOG.keys()),
        index=list(MODEL_CATALOG.keys()).index(st.session_state.get("llm_provider", "Gemini")),
        key="llm_provider",
    )
    models = MODEL_CATALOG[provider]
    model_ids = [m["id"] for m in models]

    default_model = st.session_state.get("llm_model_id", model_ids[0])
    if default_model not in model_ids:
        default_model = model_ids[0]

    model_id = st.sidebar.selectbox(
        t("model"),
        options=model_ids,
        index=model_ids.index(default_model),
        format_func=lambda m: next(x["label"] for x in models if x["id"] == m),
        key="llm_model_id",
    )

    max_tokens = st.sidebar.slider(
        t("max_tokens"), min_value=256, max_value=8192, value=int(st.session_state.get("llm_max_tokens", 4096)), step=256,
        key="llm_max_tokens",
    )
    temperature = st.sidebar.slider(
        t("temperature"),
        min_value=0.0,
        max_value=1.5,
        value=float(st.session_state.get("llm_temperature", 0.3)),
        step=0.05,
        key="llm_temperature",
    )
    system_prompt = st.sidebar.text_area(
        t("custom_prompt"),
        value=st.session_state.get("llm_system_prompt", ""),
        key="llm_system_prompt",
        height=180,
    )
    return provider, model_id, max_tokens, temperature, system_prompt


def get_llm_config():
    return (
        st.session_state.get("llm_provider", "Gemini"),
        st.session_state.get("llm_model_id", "gemini-3-flash"),
        int(st.session_state.get("llm_max_tokens", 4096)),
        float(st.session_state.get("llm_temperature", 0.3)),
        st.session_state.get("llm_system_prompt", "ä½ æ˜¯ä¸€ä½ FDA æ³•è¦åˆè¦èˆ‡ç­–ç•¥åˆ†æå°ˆå®¶ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"),
    )


# =========================
#  LLM Call Wrapper
# =========================

def call_llm(
    provider: str,
    model: str,
    system_prompt: str,
    user_messages: List[Dict[str, str]],
    max_tokens: int = 2048,
    temperature: float = 0.4,
) -> str:
    if provider == "OpenAI":
        api_key = st.session_state.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("OpenAI API key is required.")
            return ""
        client = OpenAI(api_key=api_key)
        messages = [{"role": "system", "content": system_prompt}] + user_messages
        resp = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
        )
        return resp.choices[0].message.content

    elif provider == "Gemini":
        api_key = st.session_state.get("gemini_api_key") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            st.error("Gemini API key is required.")
            return ""
        genai.configure(api_key=api_key)
        model_obj = genai.GenerativeModel(model)
        full_prompt = f"{system_prompt}\n\n" + "\n\n".join(
            f"{m['role'].upper()}: {m['content']}" for m in user_messages
        )
        resp = model_obj.generate_content(
            full_prompt,
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=max_tokens,
                temperature=temperature,
            ),
        )
        return resp.text

    elif provider == "Anthropic":
        api_key = st.session_state.get("anthropic_api_key") or os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            st.error("Anthropic API key is required.")
            return ""
        client = anthropic.Anthropic(api_key=api_key)
        messages = [m for m in user_messages if m["role"] != "system"]
        resp = client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_prompt,
            messages=[{"role": m["role"], "content": m["content"]} for m in messages],
        )
        return "".join(block.text for block in resp.content if hasattr(block, "text"))

    elif provider == "XAI (Grok)":
        # Sample XAI usage, following your reference
        api_key = st.session_state.get("xai_api_key") or os.getenv("XAI_API_KEY")
        if not api_key:
            st.error("XAI API key is required.")
            return ""
        client = XAIClient(api_key=api_key, timeout=3600)
        chat = client.chat.create(model=model)
        chat.append(xai_system(system_prompt))
        for m in user_messages:
            if m["role"] == "user":
                chat.append(xai_user(m["content"]))
        response = chat.sample()
        return response.content

    else:
        st.error("Unsupported provider.")
        return ""


# =========================
#  File Utilities
# =========================

def extract_text_from_pdf(file_bytes: BytesIO) -> str:
    reader = PdfReader(file_bytes)
    texts = []
    for page in reader.pages:
        texts.append(page.extract_text() or "")
    return "\n".join(texts)


def extract_text_from_docx(file_bytes: BytesIO) -> str:
    return docx2txt.process(file_bytes)


def extract_text_from_txt(file_bytes: BytesIO) -> str:
    return file_bytes.read().decode("utf-8", errors="ignore")


def extract_text(uploaded_file) -> str:
    name = uploaded_file.name.lower()
    data = BytesIO(uploaded_file.read())
    if name.endswith(".pdf"):
        return extract_text_from_pdf(data)
    elif name.endswith(".docx"):
        return extract_text_from_docx(data)
    elif name.endswith(".txt"):
        return extract_text_from_txt(data)
    elif name.endswith(".md"):
        return data.read().decode("utf-8", errors="ignore")
    else:
        st.error("Unsupported format. Please upload PDF, DOCX, TXT, or MD.")
        return ""


def markdown_to_pdf_bytes(md_text: str) -> bytes:
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=11)
    for line in md_text.splitlines():
        pdf.multi_cell(0, 5, line)
    pdf_bytes = BytesIO()
    pdf.output(pdf_bytes)
    pdf_bytes.seek(0)
    return pdf_bytes.getvalue()


# =========================
#  Prompts
# =========================

def build_deep_summary_prompt(doc_text: str, lang: str) -> str:
    if lang == "en":
        language_instruction = "Write the entire output in English."
    else:
        language_instruction = "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«æ•´ä»½è¼¸å‡ºï¼Œä¸¦ä»¥ FDA å¯©æŸ¥èˆ‡åˆè¦è¦–è§’é€²è¡Œæ·±å…¥åˆ†æã€‚"

    base = f"""
ä½ æ˜¯ä¸€ä½å…·å‚™ FDA è¦ç¯„ã€é†«è—¥/é†«æå¯©æŸ¥èˆ‡æˆ°ç•¥è¦åŠƒå°ˆé•·çš„ã€Œé«˜éšç­–ç•¥å¯©é–±å®˜ã€èˆ‡ã€ŒçŸ¥è­˜æ¶æ§‹å¸«ã€ã€‚
{language_instruction}

ä½ å°‡æ”¶åˆ°ä¸€ä»½æ–‡ä»¶å…§å®¹ï¼ˆå¯èƒ½ç‚ºè—¥å“ã€é†«ç™‚å™¨æã€ç”Ÿé†«çµ±è¨ˆã€è‡¨åºŠè©¦é©—ã€å“è³ªç³»çµ±ã€é¢¨éšªç®¡ç†æˆ–å…¶ä»–èˆ‡ FDA ç›¸é—œä¹‹å…§å®¹ï¼‰ã€‚
è«‹åŸ·è¡Œä»¥ä¸‹ä»»å‹™ï¼š

1. ç”¢å‡ºä¸€ä»½ **æ·±åº¦ã€çµæ§‹åŒ–çš„ Markdown å ±å‘Š**ï¼Œé•·åº¦ç´„ **2,000â€“3,000 å­—**ã€‚
2. å ±å‘Šéœ€åŒæ™‚é—œæ³¨ï¼šå…§å®¹æœ¬èº«çš„é‚è¼¯ã€FDA åˆè¦è¦é»ã€æ½›åœ¨é¢¨éšªèˆ‡ç¼ºå£ã€‚
3. ä½¿ç”¨ä»¥ä¸‹çµæ§‹ï¼ˆMarkdown æ¨™é¡Œï¼‰ï¼š

# Executive Overview / æ–‡ä»¶ç¸½è¦½
- æ–‡ä»¶ç›®çš„ã€ç›®æ¨™å°è±¡èˆ‡æ ¸å¿ƒä¸»é¡Œã€‚

## Key Themes & Regulatory Objectives / é—œéµä¸»é¡Œèˆ‡æ³•è¦ç›®æ¨™
- æ¢åˆ—æ–‡ä»¶æ¬²é”æˆä¹‹ FDA åˆè¦æˆ–ä¸Šå¸‚ç­–ç•¥ç›®æ¨™ã€‚

## Section-by-Section Analysis / é€æ®µæ·±åº¦è§£æ
- é‡å°é‡è¦æ®µè½æˆ–ç« ç¯€ï¼Œèªªæ˜ï¼š
  - ä¸»è¦å…§å®¹åœ¨è«‡ä»€éº¼ï¼Ÿ
  - èˆ‡ FDA æ³•è¦ã€å¯©æŸ¥è§€é»çš„é—œè¯ï¼Ÿ
  - æ½›åœ¨é¢¨éšªã€ç–‘é»æˆ–éœ€è¦è£œå¼·ä¹‹è™•ï¼Ÿ

## Critical Risks, Gaps, Red Flags / é—œéµé¢¨éšªèˆ‡ç¼ºå£
- å¾æ³•è¦ã€è‡¨åºŠã€CMCã€çµ±è¨ˆã€å®‰å…¨æ€§ã€æ¨™ç¤ºèˆ‡èªªæ˜æ›¸ç­‰å¤šé¢å‘ï¼Œé»å‡ºï¼š
  - é«˜ï¼ä¸­ï¼ä½é¢¨éšªé …ç›®
  - å¯èƒ½é­ FDA è³ªç–‘æˆ–è¦æ±‚è£œä»¶ä¹‹è™•ã€‚

## Actionable Recommendations / å¯åŸ·è¡Œå»ºè­°
- æ¢åˆ—å…·é«”ã€å¯æ“ä½œä¹‹ä¸‹ä¸€æ­¥ï¼š
  - ä¾‹å¦‚éœ€è£œå……å“ªäº›è©¦é©—ã€è£œå¼·å“ªäº›æ¨¡çµ„ã€å¢åŠ å“ªäº›é¢¨éšªæ§ç®¡èªªæ˜ç­‰ã€‚

## Stakeholder-Specific Views / åˆ©å®³é—œä¿‚äººè¦–è§’
- èªªæ˜å°ä»¥ä¸‹è§’è‰²çš„é‡è¦è§£è®€ï¼š
  - æ³•è¦äº‹å‹™ï¼ˆRAï¼‰
  - è‡¨åºŠèˆ‡é†«å­¸åœ˜éšŠ
  - çµ±è¨ˆèˆ‡æ•¸æ“šç§‘å­¸
  - å“è³ªèˆ‡è—¥å» ï¼å·¥å» ç‡Ÿé‹
  - ç®¡ç†éšå±¤ï¼æ±ºç­–è€…

## Glossary of Key Terms (if applicable) / å°ˆæœ‰åè©æ•´ç†
- å°‡é—œéµ FDAï¼æŠ€è¡“è¡“èªæ¢åˆ—ä¸¦åšç°¡æ˜å®šç¾©ã€‚

é™åˆ¶æ¢ä»¶ï¼š
- ä½¿ç”¨ Markdown æ¨™é¡Œï¼ˆ#ã€##ã€###ï¼‰èˆ‡æ¢åˆ—ã€‚
- å„ªå…ˆé¿å…è™›æ§‹ç‰¹å®šæ•¸æ“šï¼›å¦‚æ–‡ä»¶æœªæä¾›ï¼Œè«‹ä»¥ã€Œæ–‡ä»¶æœªæ˜ç¢ºèªªæ˜ã€æ¨™ç¤ºã€‚
- è‹¥æ–‡ä»¶å…§å®¹ä¸è¶³ä»¥æ”¯æ’çµè«–ï¼Œéœ€åœ¨æ–‡ä¸­æ¸…æ¥šè¨»æ˜ä¸ç¢ºå®šæ€§ã€‚

ä»¥ä¸‹ç‚ºæ–‡ä»¶å…§å®¹ï¼ˆå¯èƒ½å·²ç‚ºé•·åº¦è€ƒé‡è€Œæˆªæ–·ï¼‰ï¼š

[DOCUMENT START]
{doc_text[:100000]}
[DOCUMENT END]
"""
    return base.strip()


# =========================
#  Tabs
# =========================

def tab_file_transform_deep_summary():
    st.markdown(f"## {t('tab_file_transform')}")
    st.markdown('<div class="glass-panel">', unsafe_allow_html=True)

    uploaded = st.file_uploader(
        t("upload_label"),
        type=["pdf", "docx", "txt"],
        key="file_transform_uploader",
    )

    output_format = st.radio(
        t("output_format"),
        [t("format_markdown"), t("format_pdf")],
        horizontal=True,
        key="output_format_choice",
    )

    if uploaded is not None:
        if st.button(t("run_summary"), type="primary"):
            with st.spinner("Extracting text and generating deep summaryâ€¦"):
                raw_text = extract_text(uploaded)
                if not raw_text.strip():
                    st.error("No readable text extracted from the file.")
                    st.markdown("</div>", unsafe_allow_html=True)
                    return

                provider, model_id, max_tokens, temperature, system_prompt = get_llm_config()
                lang = st.session_state.get("ui_lang", "zh")

                prompt = build_deep_summary_prompt(raw_text, lang)
                output = call_llm(
                    provider=provider,
                    model=model_id,
                    system_prompt=system_prompt,
                    user_messages=[{"role": "user", "content": prompt}],
                    max_tokens=max_tokens,
                    temperature=temperature,
                )
                if not output:
                    st.markdown("</div>", unsafe_allow_html=True)
                    return

                st.session_state["latest_file_text"] = raw_text
                st.session_state["latest_file_summary_md"] = output
                st.session_state["latest_file_name"] = uploaded.name

                st.markdown("### ğŸ“„ Deep Summary (Markdown)")
                st.markdown(output)

                if output_format == t("format_markdown"):
                    st.download_button(
                        "Download Markdown",
                        data=output.encode("utf-8"),
                        file_name=f"{uploaded.name}.summary.md",
                        mime="text/markdown",
                    )
                else:
                    pdf_bytes = markdown_to_pdf_bytes(output)
                    st.download_button(
                        "Download PDF",
                        data=pdf_bytes,
                        file_name=f"{uploaded.name}.summary.pdf",
                        mime="application/pdf",
                    )

    if "latest_file_text" in st.session_state:
        st.markdown("---")
        st.markdown(f"### ğŸ’¬ {t('chat_with_file')} â€” {st.session_state.get('latest_file_name', '')}")
        user_q = st.text_area(t("user_prompt"), key="file_chat_prompt")
        if st.button("Ask the file"):
            provider, model_id, max_tokens, temperature, system_prompt = get_llm_config()
            full_context = f"""
ä»¥ä¸‹æ˜¯åŸå§‹æ–‡ä»¶å…§å®¹èˆ‡è©²æ–‡ä»¶ä¹‹é•·ç¯‡æ‘˜è¦ã€‚è«‹åš´æ ¼æ ¹æ“šæ­¤ç­‰è³‡è¨Šä½œç­”ï¼Œè‹¥å…§å®¹ä¸è¶³ä»¥æ”¯æŒç­”æ¡ˆï¼Œè«‹æ˜ç¢ºèªªæ˜ã€Œæ–‡ä»¶æœªæä¾›è¶³å¤ è³‡è¨Šã€ã€‚

[ORIGINAL DOCUMENT]
{st.session_state['latest_file_text'][:60000]}

[SUMMARY]
{st.session_state['latest_file_summary_md'][:40000]}
"""
            question = user_q.strip()
            if not question:
                st.warning("è«‹è¼¸å…¥å•é¡Œã€‚")
            else:
                with st.spinner("Thinking with the documentâ€¦"):
                    answer = call_llm(
                        provider=provider,
                        model=model_id,
                        system_prompt=system_prompt,
                        user_messages=[
                            {"role": "user", "content": full_context},
                            {"role": "user", "content": question},
                        ],
                        max_tokens=max_tokens,
                        temperature=temperature,
                    )
                st.markdown("#### Answer")
                st.markdown(answer or "_No answer produced._")

    st.markdown("</div>", unsafe_allow_html=True)


def tab_file_intelligence():
    st.markdown(f"## {t('tab_file_intel')}")
    st.markdown('<div class="glass-panel">', unsafe_allow_html=True)
    up = st.file_uploader(
        t("upload_label"),
        type=["pdf", "docx", "txt", "md"],
        key="file_intel_uploader",
    )
    if up is not None and st.button("Analyze File"):
        with st.spinner("Analyzing fileâ€¦"):
            text = extract_text(up)
            provider, model_id, max_tokens, temperature, system_prompt = get_llm_config()
            lang = st.session_state.get("ui_lang", "zh")

            language_instruction = (
                "Write the output in English."
                if lang == "en"
                else "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œä¸¦ä»¥ FDA å¯©æŸ¥èˆ‡åˆè¦è§€é»é€²è¡Œèªªæ˜ã€‚"
            )
            prompt = f"""
ä½ æ˜¯ä¸€ä½ FDA æ³•è¦ã€è‡¨åºŠèˆ‡ CMC æ•´åˆåˆ†æå°ˆå®¶ã€‚
{language_instruction}

è«‹é‡å°ä»¥ä¸‹æ–‡ä»¶é€²è¡Œçµæ§‹åŒ–åˆ†æï¼Œæ¶µè“‹ï¼š
- æ–‡ä»¶ç›®çš„èˆ‡é©ç”¨é ˜åŸŸ
- èˆ‡ FDA ç›¸é—œçš„æ³•è¦æˆ–æŒ‡å¼•ï¼ˆå¦‚ 21 CFRã€GxPã€ICH æŒ‡å—ï¼‰ä¹‹é—œè¯
- æ½›åœ¨é¢¨éšªèˆ‡ç¼ºå£
- å»ºè­°è£œå¼·èˆ‡ä¸‹ä¸€æ­¥è¡Œå‹•

[DOCUMENT START]
{text[:100000]}
[DOCUMENT END]
"""
            result = call_llm(
                provider=provider,
                model=model_id,
                system_prompt=system_prompt,
                user_messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature,
            )
            st.markdown("### Analysis")
            st.markdown(result or "_No output._")
    st.markdown("</div>", unsafe_allow_html=True)


def tab_multi_file_synthesis():
    st.markdown(f"## {t('tab_multi_file')}")
    st.markdown('<div class="glass-panel">', unsafe_allow_html=True)
    files = st.file_uploader(
        "Upload multiple files (PDF/DOCX/TXT/MD)",
        type=["pdf", "docx", "txt", "md"],
        accept_multiple_files=True,
        key="multi_files",
    )
    if files and st.button("Combine & Analyze"):
        with st.spinner("Combining and analyzing filesâ€¦"):
            assembled = []
            for f in files:
                content = extract_text(f)
                assembled.append(
                    f"--- START FILE: {f.name} ---\n{content}\n--- END FILE: {f.name} ---\n"
                )
            combined = "\n".join(assembled)[:150000]

            provider, model_id, max_tokens, temperature, system_prompt = get_llm_config()
            lang = st.session_state.get("ui_lang", "zh")
            language_instruction = (
                "Write the output in English."
                if lang == "en"
                else "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œä¸¦å¼·èª¿è·¨æ–‡ä»¶ä¹‹ FDA æ³•è¦è§€é»èˆ‡å·®ç•°ã€‚"
            )

            prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆç²¾æ–¼ FDA å ±è¦èˆ‡è·¨æ–‡ä»¶ç­–ç•¥è©•ä¼°çš„é¡§å•ã€‚

{language_instruction}

ä½ å°‡æ”¶åˆ°å¤šä»½æ–‡ä»¶ï¼Œå·²ä»¥ START/END FILE æ¨™è¨˜å€åˆ†ã€‚
è«‹è¦–å…¶ç‚ºä¸€çµ„ã€ŒçŸ¥è­˜åº«ã€ï¼ŒåŸ·è¡Œä»¥ä¸‹ä»»å‹™ï¼š

- æ¯”è¼ƒèˆ‡å°ç…§å„æ–‡ä»¶åœ¨æ³•è¦ç«‹å ´ã€è‡¨åºŠè­‰æ“šã€CMCã€é¢¨éšªç®¡ç†ç­‰é¢å‘çš„å·®ç•°èˆ‡ä¸€è‡´æ€§ã€‚
- æ‰¾å‡ºé—œéµè½å·®ï¼ˆä¾‹å¦‚ CTD æ¨¡çµ„é–“å‰å¾Œä¸ä¸€è‡´ã€çµ±è¨ˆå‡è¨­èˆ‡å¯¦éš›åˆ†æä¸ç¬¦ã€èªªæ˜æ›¸èˆ‡æ¨™ç¤ºä¸ä¸€è‡´ç­‰ï¼‰ã€‚
- ç”¢å‡º Markdown å ±å‘Šï¼ŒåŒ…å«ï¼š
  - Executive Summaryï¼ˆæ•´é«”çµè«–ï¼‰
  - Cross-Document Comparisonsï¼ˆè·¨æ–‡ä»¶æ¯”è¼ƒï¼‰
  - Key Risks / Gapsï¼ˆé¢¨éšªèˆ‡ç¼ºå£ï¼‰
  - FDA å¯©æŸ¥è§€é»ä¸‹çš„å„ªå…ˆé †åºèˆ‡å»ºè­°ä¸‹ä¸€æ­¥

[DOCUMENTS]
{combined}
"""
            result = call_llm(
                provider=provider,
                model=model_id,
                system_prompt=system_prompt,
                user_messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature,
            )
            st.markdown("### Synthesis Report")
            st.markdown(result or "_No output._")
    st.markdown("</div>", unsafe_allow_html=True)


def tab_smart_replace():
    st.markdown(f"## {t('tab_smart_replace')}")
    st.markdown('<div class="glass-panel">', unsafe_allow_html=True)
    col1, col2 = st.columns(2)
    with col1:
        template_text = st.text_area(
            "Template (with placeholders like [Product Name], [Indication])",
            height=260,
        )
    with col2:
        context_text = st.text_area(
            "Context / Raw Data Source (e.g., protocol, CSR, CMC summary)",
            height=260,
        )

    instructions = st.text_area(
        "Natural language instructions (tone, style, constraints)",
        value="è«‹ä¾ç…§ FDA æ³•è¦èˆ‡ç§‘å­¸åˆç†æ€§å¡«å¯«æ‰€æœ‰æ¬„ä½ï¼Œç¶­æŒå°ˆæ¥­ã€ç²¾ç¢ºä¸”å¯©æŸ¥å‹å–„çš„èªæ°£ã€‚",
    )

    if st.button("Run Smart Replace"):
        provider, model_id, max_tokens, temperature, system_prompt = get_llm_config()
        lang = st.session_state.get("ui_lang", "zh")
        language_instruction = (
            "Write the output in English."
            if lang == "en"
            else "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«å®Œæ•´ç¯„æœ¬å…§å®¹ã€‚"
        )

        prompt = f"""
ä½ æ˜¯ä¸€ä½ FDA å ±è¦èˆ‡æ³•å¾‹æ–‡æœ¬æ’°å¯«å°ˆå®¶ã€‚

{language_instruction}

ä¸‹åˆ—ç‚ºä¸€ä»½å«æœ‰å ä½ç¬¦çš„ç¯„æœ¬ï¼ˆå¦‚ [Product Name]ã€[Indication]ã€[Dosage] ç­‰ï¼‰ï¼š

[TEMPLATE]
{template_text}

ä»¥ä¸‹ç‚ºæœªçµæ§‹åŒ–çš„èƒŒæ™¯è³‡æ–™ï¼ˆå¯èƒ½ä¾†è‡ª ICH CTD æ¨¡çµ„ã€è‡¨åºŠè©¦é©—è¨ˆç•«ã€CMC æ–‡ä»¶ã€é¢¨éšªç®¡ç†è¨ˆç•«ç­‰ï¼‰ï¼š
[CONTEXT]
{context_text}

ä½¿ç”¨è€…çµ¦ä½ çš„é¡å¤–èªªæ˜èˆ‡åå¥½ï¼ˆèªæ°£ã€é¢¨æ ¼ã€é™åˆ¶ï¼‰å¦‚ä¸‹ï¼š
{instructions}

è«‹ä¾æ“š CONTEXT ä¸­å¯åˆç†æ¨è«–ä¹‹è³‡è¨Šï¼š
- è£œé½Šæ‰€æœ‰å ä½ç¬¦
- é¿å…æ†‘ç©ºæé€ é—œéµæ•¸æ“šï¼›è‹¥æ–‡ä»¶æœªæä¾›ï¼Œè«‹ä»¥ã€Œï¼ˆæ–‡ä»¶æœªæä¾›æ˜ç¢ºè³‡è¨Šï¼‰ã€æ¨™ç¤º
- èª¿æ•´å‘¨é‚Šæ–‡å­—ï¼Œä½¿å…¨æ–‡åœ¨èªæ³•èˆ‡æ³•è¦èªæ°£ä¸Šè‡ªç„¶ã€é€£è²«
- ä»¥ Markdown è¼¸å‡ºå®Œæ•´ä¸”å·²å¡«å¯«å®Œæˆä¹‹ç¯„æœ¬
"""
        with st.spinner("Generating filled templateâ€¦"):
            result = call_llm(
                provider=provider,
                model=model_id,
                system_prompt=system_prompt,
                user_messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature,
            )
        st.markdown("### Completed Template")
        st.markdown(result or "_No output._")
    st.markdown("</div>", unsafe_allow_html=True)


def tab_ai_note_keeper():
    st.markdown(f"## {t('tab_note_keeper')}")
    st.markdown('<div class="glass-panel">', unsafe_allow_html=True)

    raw_note = st.text_area("Your raw notes / brain dump", height=240, key="note_raw")
    col1, col2, col3, col4, col5 = st.columns(5)
    action = None
    if col1.button("Format"):
        action = "format"
    if col2.button("Tasks"):
        action = "tasks"
    if col3.button("Fix"):
        action = "fix"
    if col4.button("Summary"):
        action = "summary"
    if col5.button("Expand"):
        action = "expand"

    if action and raw_note.strip():
        provider, model_id, max_tokens, temperature, system_prompt = get_llm_config()
        lang = st.session_state.get("ui_lang", "zh")
        language_instruction = (
            "Write the output in English."
            if lang == "en"
            else "è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ï¼Œä¸¦ç¶­æŒ FDA å ±è¦æˆ–å°ˆæ¥­å¯©æŸ¥æ–‡ä»¶å¸¸è¦‹ä¹‹èªæ°£ã€‚"
        )

        prompt_map = {
            "format": "å°‡é€™äº›ç­†è¨˜æ•´ç†æˆçµæ§‹æ¸…æ¥šçš„ Markdownï¼ˆå«æ¨™é¡Œèˆ‡æ¢åˆ—ï¼‰ï¼Œæ–¹ä¾¿æ—¥å¾Œç”¨æ–¼ FDA æ–‡ä»¶è‰æ“¬ã€‚",
            "tasks": "å¾é€™äº›å…§å®¹ä¸­èƒå–æ‰€æœ‰å¯åŸ·è¡Œä»»å‹™ï¼Œä¸¦ä»¥æ ¸å–æ¸…å–® (- [ ]) æ¢åˆ—ï¼Œè‘—é‡æ–¼ FDA å ±è¦èˆ‡åˆè¦è¡Œå‹•ã€‚",
            "fix": "ä¿®æ­£æ–‡æ³•ã€ç”¨è©èˆ‡é‚è¼¯ï¼Œä½¿å…¶æ›´é©åˆä½œç‚ºå° FDA æˆ–å…§éƒ¨å¯©æŸ¥ä½¿ç”¨çš„å°ˆæ¥­æ–‡å­—ã€‚",
            "summary": "å…ˆçµ¦å‡ºä¸€æ®µç²¾ç°¡ TL;DR æ‘˜è¦ï¼Œå†ä»¥æ¢åˆ—æ–¹å¼æ•´ç†é‡é»èˆ‡é¢¨éšªé …ç›®ã€‚",
            "expand": "å°‡ç°¡çŸ­çš„è¦é»æ“´å¯«æˆè¼ƒå®Œæ•´çš„æ®µè½ï¼Œä¸¦åŠ å…¥ FDA åˆè¦è§€é»æˆ–å¯¦å‹™å»ºè­°ã€‚",
        }
        prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆé–€å”åŠ© FDA å ±è¦åœ˜éšŠæ•´ç†æ€è·¯çš„ã€ŒçŸ¥è­˜ç®¡ç†é¡§å•ã€ã€‚

{language_instruction}

ä½¿ç”¨è€…çš„åŸå§‹ç­†è¨˜å¦‚ä¸‹ï¼š
{raw_note}

ä»»å‹™ï¼š{prompt_map[action]}

è«‹åªè¼¸å‡ºæ•´ç†å¾Œçš„ Markdown ç­†è¨˜ã€‚
"""
        with st.spinner("Transforming notesâ€¦"):
            result = call_llm(
                provider=provider,
                model=model_id,
                system_prompt=system_prompt,
                user_messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=temperature,
            )
        st.markdown("### Transformed Notes")
        st.markdown(result or "_No output._")
    st.markdown("</div>", unsafe_allow_html=True)


# =========================
#  Main
# =========================

def main():
    st.set_page_config(
        page_title="AuditFlow AI Â· Masterpiece Edition (FDA)",
        layout="wide",
    )

    # Init session defaults
    if "ui_lang" not in st.session_state:
        st.session_state.ui_lang = "zh"
    if "dark_mode" not in st.session_state:
        st.session_state.dark_mode = True
    if "artist_style_key" not in st.session_state:
        st.session_state.artist_style_key = "van_gogh"

    # Load agents
    agents = load_agents()

    # Sidebar global controls
    with st.sidebar:
        st.markdown("## ğŸŒ Global Settings")
        lang_label = st.radio("Language / èªè¨€", ["English", "ç¹é«”ä¸­æ–‡"], key="lang_radio")
        st.session_state.ui_lang = "en" if lang_label == "English" else "zh"

        dark_mode = st.toggle("Dark mode", value=st.session_state.dark_mode, key="dark_mode_toggle")
        st.session_state.dark_mode = dark_mode

        active_style = style_selector_ui()
        render_api_key_inputs()
        selected_agent = agent_selector_ui(agents)
        render_llm_controls()

    # Apply painter theme
    apply_theme(active_style, st.session_state.dark_mode)

    # Header
    st.markdown(f"<h1 class='accent-title'>{t('app_title')}</h1>", unsafe_allow_html=True)
    st.markdown(t("subtitle"))
    if selected_agent:
        st.markdown(
            f"<div class='accent-chip'>ç›®å‰ä»£ç†äººï¼š{selected_agent.get('display_name_zh','')}</div>",
            unsafe_allow_html=True,
        )

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        t("tab_file_transform"),
        t("tab_file_intel"),
        t("tab_multi_file"),
        t("tab_smart_replace"),
        t("tab_note_keeper"),
    ])

    with tab1:
        tab_file_transform_deep_summary()
    with tab2:
        tab_file_intelligence()
    with tab3:
        tab_multi_file_synthesis()
    with tab4:
        tab_smart_replace()
    with tab5:
        tab_ai_note_keeper()


if __name__ == "__main__":
    main()
